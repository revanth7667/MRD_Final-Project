---
title: "LAPD Crime Data Analysis - Poisson(Group 13)"
documentclass : report
echo: FALSE
editor: visual
message: FALSE
warning: FALSE
output:
 pdf_document:
  latex_engine: xelatex
 top-margin: 1in
geometry: margin = 3.175cm
format: pdf
---

```{r}
#Loading all libraries
library(lubridate)
library(dplyr)
library(tidyverse)
library(AER)

# Resolve package conflicts
library(conflicted)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
```

## Overview

In this section of the report, we present the second research question: **"What is the predicted number of crimes for a given area and time period?"** Addressing this question, we employ Poisson regression modeling, a choice driven by the count nature of our outcome variable and the need for predictive accuracy. Our model integrates various predictors, including the time and date of crime occurrences and geographic factors, to estimate the likelihood of crime counts in specific areas and time periods. We also explore potential interactions, such as between the day of the week and specific dates (e.g., holidays), to enhance the model's contextual relevance.

Given the dataset from the Los Angeles Police Department (LAPD), focusing on the period from 2020 to the present day, we look for predictive insights through the unfornuate individual crime incidents in Los Angeles. There are a wide array of variables such as location coordinates, victim demographics, crime descriptions, and date-time stamps, that provide a rich foundation for our exploratory and predictive analyses.

Our Poisson regression analysis on the Los Angeles Police Department's crime data reveals significant temporal and spatial variations in crime incidents. The model, with an R-squared value of 0.8246298, indicates a strong predictive performance, substantiated by the close alignment of the mean daily crime count estimate of 450.6 with the predicted values. Notably, areas like Devonshire and Foothill exhibit a lower incidence of crimes, as reflected by negative coefficients, while the Central area shows a slight increase. Weekday and month indicators suggest crime occurrences fluctuate with time, peaking in certain months and on specific days of the week, providing critical insights for targeted law enforcement deployment and community safety initiatives.

```{r, include=FALSE}
#Load the dataset
file_url <- "https://www.dropbox.com/scl/fi/x9frb64wqo2wzhdwq79j7/LAPD_crime_final.csv?rlkey=b4tekpat0v2tl8ar4it6ahqe3&dl=1"

pre_df <- read.csv(file_url)

#head(pre_df)
```

## Introduction

Crime persists as a complex social issue with far-reaching implications, necessitating a rigorous analysis to inform public safety strategies. This report leverages an extensive dataset provided by the Los Angeles Police Department (LAPD), encompassing 820,599 crime reports. The granularity of the dataset allows for a detailed exploration of crime patterns across various dimensions, wherein each row of the datset contains location coordinates, area specifics, victim demographics such as age, gender, and ethnicity, crime specifics including type, investigative outcomes, and weapons involved, as well as temporal data like reporting and occurrence dates with corresponding times, all uniquely identified by record identifiers and mocodes.:

The focus of our statistical investigation addresses pivotal questions concerning the predictors of crime severity and the forecast of crime occurrences. Specifically, the second research question, **"What is the predicted number of crimes for a given area and time period?"** is crucial for allocating resources and enhancing preventative measures. By employing a Poisson regression model, we aim to dissect the frequency of crimes within the multifaceted urban setup of Los Angeles, identifying temporal and spatial hotspots of criminal activity.

Given the prediction nature, we've narrowed down our model to the following variables:

List of Predictor Variables

-   Independent Variables

    \- Time and Date: Time Occurred, Date Occurred

    \- Geographic Factor: Area

<!-- -->

-   Outcome Variable

    \- Count of Crimes (Generated by grouping the dataset by the selected predictor variables)

Understanding the dynamics of crime distribution is invaluable for law enforcement agencies, policymakers, and the broader community. It allows for a data-driven approach to crime prevention and the optimization of policing efforts. Moreover, deciphering the patterns in which crime manifests can lead to more effective community outreach programs and the potential to mitigate risk factors associated with crime. Our research contributes to this domain by offering empirical insights into the patterns of crime, which in turn could guide evidence-based resource allocation.

```{r, include=FALSE}
#Creating a dataframe of selected columns from pre_df
df <- pre_df %>% 
  select(DR_NO,DATE.OCC,AREA,AREA.NAME,Part.1.2,Vict.Age,Vict.Sex,Vict.Descent)

#head(df)
```

```{r, include=FALSE}
#Operations on the datacolumn
df$DATE.OCC <- substr(df$DATE.OCC,1,10) 
df$DATE.OCC <- as.Date(df$DATE.OCC, "%m/%d/%Y")
#Calculate Year, Month and Day
#df$dt_year = format(df$DATE.OCC,"%Y")
df$dt_month = as.factor(format(df$DATE.OCC,"%m"))


#df$dt_day = format(df$DATE.OCC,"%d")
df$dt_weekday <- as.factor(wday(df$DATE.OCC, label=TRUE))
#df$DATE.OCC <- as.Date(format(df$DATE.OCC, "%m/%Y-01"), "%m/%Y-01")
#df$DATE.OCC <- format(df$DATE.OCC, "%Y-%m")
#df$Date.Rptd <- substr(df$Date.Rptd,1,10) 
#df$Date.Rptd <- as.Date(df$Date.Rptd, "%m/%d/%Y")

#df$rpt_diff <- df$Date.Rptd- df$DATE.OCC
```

```{r, include=FALSE}
#Creating a dataframe with groupby.  
df_daily <- df %>%
  group_by(dt_weekday,dt_month,AREA,AREA.NAME)%>%
  summarise(count = n())

#head(df_daily)
```

```{r, include=FALSE}
#Verify no missing values
missing_counts <- colSums(is.na(df_daily))
#missing_counts
```

### Crime Count Distributions by Weekday and Proportions

The composite visualization below merges two distinct perspectives on crime data: the aggregated crime counts by weekday and the proportional distribution of crime counts. On one side, the bar chart delineates the frequency of crimes for each day of the week, providing insights into the daily patterns of crime occurrence within the city of Los Angeles.

```{r}
#| fig-width: 5.5
#| fig-height: 2
library(gridExtra)
library(ggplot2)
library(dplyr)

# Create the histogram plot
p1 <- ggplot(df_daily, aes(x = count, y = ..density..)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  labs(title = "Crime Counts (Proportions)",
       x = "Crime Count",
       y = "Proportion") +
  theme_minimal()

# Aggregate counts by weekday across all areas and months
weekday_counts <- df_daily %>%
  group_by(dt_weekday) %>%
  summarise(total_count = sum(count))

# Create the bar chart for weekday counts
p2 <- ggplot(weekday_counts, aes(x = dt_weekday, y = total_count, fill = dt_weekday)) +
  geom_bar(stat = "identity") +
  labs(title = "Crime Counts Weekday",
       x = "Day of the Week",
       y = "Total Count Crimes") +
  theme_minimal() +
  theme(legend.position = "none")

# Adjust plot margins
margin_adjustment <- theme(plot.margin = margin(5, 5, 5, 5, "pt"))
p1 <- p1 + margin_adjustment
p2 <- p2 + margin_adjustment

# Define a layout matrix to arrange the plots
# Here we arrange p1 on the left and p2 on the right in a single row
layout_matrix <- matrix(c(1, 2), nrow = 1)

# Use grid.arrange to display the plots side by side
grid.arrange(p1, p2, layout_matrix = layout_matrix, 
             top="Crime Count Distributions")
```

## Methods

This section outlines the analytical procedures employed to address the research question 'what is the predicted number of crimes for a given area and time period?' posed by our study of the Los Angeles Police Department's crime data. Our methodology was designed to provide insights into crime patterns and to predict the number of crimes in a given area and time period.

**Data Ingestion and Exploratory Data Analysis (EDA):**

The crime dataset, sourced from the Los Angeles Police Department and publicly available via Dropbox, was then ingested into our R environment. This dataset underwent an initial cleaning process where we selected only the most relevant columns, including crime record numbers, dates of occurrence, area identifiers, and victim demographics.

The EDA was an integral preliminary phase where we immersed ourselves in the LAPD crime dataset to understand its intricacies and prepare it for in-depth analysis. Our EDA encompassed a multifaceted approach:

1.  **Data Familiarization**: We began by acquainting ourselves with the dataset's structure, which comprised 820,599 observations and 28 variables, encapsulating a comprehensive range of crime-related information.

2.  **Data Integrity Checks**: We conducted checks for missing values, particularly within victim demographics, recognizing that missing data could introduce bias or affect our models' robustness. Where missingness was systematic and substantial, we discussed potential strategies for imputation or cautious exclusion.

3.  **Visual Exploration**: Our EDA involved the creation of bar plots and time series graphs to visualize the distribution of crime types, daily crime counts, and observe trends and outliers. This visual exploration allowed us to detect any peculiar patterns or anomalies, such as unexpected spikes in crime counts on specific days.

4.  **Variable Relationships**: We assessed the relationships between various variables, including the time of crime occurrences (time of day, day of the week, and month), location (proximity to precincts), and victim demographics (age, gender, ethnicity). Through this, we observed minor variations in crime distribution, with more pronounced differences at certain times of the day.

5.  **Outcome Variable Creation**: From the EDA, we derived crucial outcome variables. The **`crime type`** variable categorized crimes into serious and non-serious, providing a binary classification for further inferential statistics. Additionally, we aggregated the data to construct a daily crime count variable, offering a continuous measure for our predictive models.

6.  **Data Cleaning and Preparation**: Variables not pertinent to our research, such as crime record identifiers and redundant information, were excluded. We also addressed categorical variables with numerous levels by consolidating them under broader categories to simplify our analyses and reduce model complexity.

```{r, include=FALSE}
#stepwise and cross-validation setup 
library(caret)
library(caTools) 
set.seed(123)

split<-sample.split(df_daily$count,SplitRatio = 0.7)
train<-subset(df_daily,split==TRUE)
test<-subset(df_daily,split ==FALSE)
```

```{r, include=FALSE}
#Fitting the model
model <- glm(count ~ AREA.NAME+dt_weekday+dt_month , data = train, family = poisson)
model_forward <- step(model, direction = "both")
summary(model_forward)
```

```{r, include=FALSE}
#Testing the model, evaluation 
dispersiontest(model_forward)
```

**Modeling and Preliminary Insights:**

The decision to utilize Poisson regression was underpinned by the nature of our dependent variable, which counts the number of crimes---a typical example where Poisson regression is deemed appropriate due to its count-based distribution assumptions.

In constructing the model, we included area name, day of the week, and month as independent variables, hypothesizing that these factors significantly impact crime rates. A stepwise selection method, guided by the Akaike Information Criterion (AIC), was instrumental in refining our model. This iterative process of variable inclusion and exclusion allowed us to identify the most statistically significant predictors while maintaining model parsimony.

Preliminary examination of the model outputs suggests distinct spatial and temporal crime patterns. Certain areas, indicated by negative coefficients, such as Devonshire and Foothill, were associated with lower crime rates relative to the baseline, while the Central area showed a higher propensity for crime occurrences, as suggested by its positive coefficient. Moreover, the day of the week and month variables revealed variations in crime occurrences, with specific days and months exhibiting notable deviations from the average crime count. For example, coefficients for certain months, like September through December, pointed to a significant decrease in crime counts, potentially reflecting seasonal crime trends.

(AIC - 15358) - Work in Progress, TBD

(Overdisperson) - Work in Progress, TBD

Our preliminary evaluation of the model's predictive accuracy, gauged through the RMSE, yielded a value of 42.58718. This metric provides an estimate of the average difference between the predicted and observed crime counts, and is particularly useful for stakeholders to grasp the model's performance in concrete terms.

Additionally, the R-squared value of 0.8246298 reflected a strong linear relationship between the observed and predicted crime counts, explaining a substantial proportion of the variance in the crime data.

```{r, include=FALSE}
# Predicting the outputs
predictions <- predict(model_forward, newdata = test, type='response')

# Add predictions to the test dataset
test$predict <- predictions

# Display the first few rows of the test dataset with predictions
head(test)

# Summary of the model with exponentiated coefficients, confidence intervals, and p-values
exp_coef <- exp(coef(model_forward))
conf_int <- exp(confint(model_forward))
p_values <- summary(model_forward)$coefficients[, 4]

# Combine the exponentiated coefficients with their corresponding confidence intervals and p-values
results_summary <- cbind(exp_coef, conf_int, p_values)
```

```{r, include=FALSE}
#library(caret)
#set.seed(40000) 

#train_control <- trainControl(method = "cv",
                                          #number = 10)

#mod <- train(count ~ AREA.NAME +dt_month+dt_weekday, 
             #data = df_daily,
             #method = "glmStepAIC",
             #family = poisson,  # Remove quotes around poisson
             #trControl = train_control)
#get model metrics
#print(mod)
```

```{r, include=FALSE}
library(Metrics)
#test$count <- as.integer(test$count)
#test$predict <- as.integer(test$predict)

rmse(test$count, test$predict)
```

```{r, include=FALSE}
rsq <- function (x, y) cor(x, y) ^ 2
rs <- rsq(test$count, test$predict)
rs
```

```{r, include=FALSE}
summary(test$count)
```

```{r, include=FALSE}
summary(test$predict)
#we can't use avg, we use rmse 
```

## Results(WIP)

Our analysis using a Poisson regression model has yielded preliminary insights that are promising in addressing our research question: "What is the predicted number of crimes for a given area and time period?" The initial results point towards significant spatial and temporal effects on crime rates within the city of Los Angeles.

From the model outputs, two insights emerge at first glance. Firstly, the area named 'Central' has a higher relative crime rate compared to the baseline, which suggests that this area experiences a greater frequency of reported crimes. Secondly, the coefficients for the months indicate seasonal variations, with certain months like September showing a marked decrease in crime occurrences. These patterns are critical for understanding the ebb and flow of crime across the city and may provide valuable guidance for law enforcement resource allocation.

(NOTE: These results are placeholders and preliminary, they offer a starting point for further discussion with professor Andrea to refine the model and interpret the findings accurately.)
