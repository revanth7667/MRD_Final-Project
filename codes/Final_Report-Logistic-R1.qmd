---
title: "Los Angeles Crime Analysis"
author: 
format: pdf
editor: visual
echo: FALSE
output: FALSE
geometry: margin = 1.0cm
---

```{r}
#Load all the required packages and libraries
library(AER)
library(car)
library(caret)
library(caTools)
#library(corrplot)
#library(cvms)
library(dplyr)
library(geosphere)
#library(ggmap)
library(ggplot2)
#library(ggpubr)
library(gridExtra)
library(gtsummary)
#library(knitr)
#library(leaflet)
library(lubridate)
#library(maps)
library(Metrics)
#library(openintro)
library(pROC)
#library(purrr)
#library(stargazer)
#library(stringr)
library(tidyverse)

# Resolve package conflicts
#library(conflicted)
#conflict_prefer("filter", "dplyr")
#conflict_prefer("lag", "dplyr")
```

```{r}
#Load the data
df_precinct <- read.csv("/Users/suimp/OneDrive/Desktop/Duke University/Class/2023-Fall/IDS 702 Modeling and Representation of Data/Team Project/Final/Precinct_Location.csv")
df <- read.csv('/Users/suimp/OneDrive/Desktop/Duke University/Class/2023-Fall/IDS 702 Modeling and Representation of Data/Team Project/Final/crime/crime.csv') #change this path later
```

```{r}
str(df)
```

```{r}
#Date Related Cleanings
#Clean the Data Columns and create difference
df$DATE.OCC <- substr(df$DATE.OCC,1,10) 
df$DATE.OCC <- as.Date(df$DATE.OCC, "%m/%d/%Y")

df$Date.Rptd <- substr(df$Date.Rptd,1,10) 
df$Date.Rptd <- as.Date(df$Date.Rptd, "%m/%d/%Y")

df$rpt_diff <- df$Date.Rptd- df$DATE.OCC
```

Important Step here, Adjust if required:

```{r}
#Dropping data after Sept-2023 as this may give outlier as seen during EDA, adjust to Oct-01 if required
df <- df[df$DATE.OCC < as.Date("09/01/2023", "%m/%d/%Y"), ]
```

```{r}
#Calculate Year, Month and Day
df$dt_year = format(df$DATE.OCC,"%Y")
df$dt_month = as.factor(format(df$DATE.OCC,"%m"))
df$dt_day = format(df$DATE.OCC,"%d")
df$dt_weekday <- as.factor(wday(df$DATE.OCC, label=TRUE))
```

```{r}
#Calculate Distance to Precinct in Miles
df <- df %>% left_join( df_precinct[,c("precinct_code","precinct_lat","precinct_long")], 
        by=c('AREA'='precinct_code'))

df$dist_to_precinct <- distHaversine(df[,c("LON","LAT")],df[,c("precinct_long","precinct_lat")])*0.00062137
```

```{r}
#create text column for crime_type
df$crime_type <- as.factor(ifelse(df$Part.1.2==1,"serious","non-serious"))
```

```{r}
#clean time 
df$time_hr <- as.integer(substr(str_pad(as.character(df$TIME.OCC),4,pad=0),1,2))
```

```{r}
#create binary column if weapon is involved
df$weapons_binary <- as.factor(ifelse(is.na(df$Weapon.Used.Cd) | (df$Weapon.Used.Cd==""),0,1))
```

```{r}
#Performing the following Cleanings as per Suim's Logistic Regression requirements

#Cleaning Descent
df$Vict.Descent[df$Vict.Descent == ""] <- "X"
df$Vict.Descent[df$Vict.Descent == "-"] <- "X"
df$Vict.Descent <- as.factor(df$Vict.Descent)

#Cleaning Gender 
df$Vict.Sex[df$Vict.Sex == ""] <- "X"
df$Vict.Sex[df$Vict.Sex == "-"] <- "X"
df$Vict.Sex <- as.factor(df$Vict.Sex)
```

## EDA

```{r}
ggplot(df, aes(x = crime_type, fill = crime_type)) +
  geom_bar() +
  labs(title = "Distribution of Crime Types", x = "Crime Types", y = "Count") +
  geom_text(aes(label = after_stat(count)), stat = "count", vjust = 1.5) +   # Adjusted the vertical position of the text
  #scale_fill_manual(values = c("non-serious" = "#88DD88", "serious" = "#FF6666")) +  # Dimmed shades of green and red
  theme(legend.position = "none",      # Remove the legend
        plot.title = element_text(hjust = 0.5))  # Center the title
```

```{r}
daily_crime_count <- df %>%
  group_by(DATE.OCC) %>%
  summarize(Count = n()) %>%
  arrange(DATE.OCC)

# Calculate the average value
avg_value <- mean(daily_crime_count$Count)

ggplot(data = daily_crime_count, aes(x = DATE.OCC, y = Count)) +
  geom_line(color = "#4A90E2") +  
  labs(title = "Daily Crime Counts", x = "Date The Crime Occurred", y = "Count") +
  geom_hline(yintercept = avg_value, linetype = "dashed", color = "red") +
  geom_text(aes(x = max(DATE.OCC), y = avg_value + max(Count) * 0.02, 
                label = paste("Average:", round(avg_value, 0))), 
            color = "red", hjust = 0.78) +
  theme(legend.position = "none",      
        plot.title = element_text(hjust = 0.5),   
        axis.title.x = element_text(size=12), 
        axis.title.y = element_text(size=12))
```

```{r}
#Time, Day and Month
q1 <- ggplot(df, aes(x=time_hr, fill=crime_type))+
  geom_histogram(binwidth = 1, position="dodge", alpha=0.7)+
  labs(title = NULL, x = "Time of Day (24-Hour)", y = "Count") +
  scale_fill_discrete(name="Crime Type")  # Set legend title

q2 <- ggplot(df, aes(x=dt_weekday, fill=crime_type))+
  geom_bar(position="dodge")+
  labs(title = NULL, x = "Weekday", y = "Count") +
  theme(legend.position="none")

q3 <- filter(df, dt_year != 2023) %>%
  ggplot(aes(x=dt_month, fill=crime_type))+
  geom_bar(position="dodge")+
  labs(title = NULL, x = "Month", y = 'Count')+
  theme(legend.position="none")
```

```{r}
# Adjust the plot margins
margin_adjustment <- theme(plot.margin = margin(5, 5, 5, 5, "pt"))
q1 <- q1 + margin_adjustment
q2 <- q2 + margin_adjustment
q3 <- q3 + margin_adjustment

# Define a layout matrix
# The numbers in the matrix correspond to the plots:
# 1 = q3, 2 = q2, 3 = q1
# The layout matrix arranges q3 and q2 side by side in the first row,
# and q1 (stretched) in the second row.
layout_matrix <- rbind(c(1, 2),
                      c(3, 3)) # Stretching q1 across the width of the grid

# Combine the plots using the custom layout
grid.arrange(q3, q2, q1, layout_matrix = layout_matrix, 
             top="Crime Distribution by Month, Weekday, and Time of Day")
```

```{r}
# First plot
p1 <- ggplot(df, aes(x = AREA.NAME, fill = crime_type)) +
  geom_bar(position = "dodge", alpha = 0.7) +
  labs(x = "Precinct", y = "Count", fill = "Crime Type") +  # Removed title to avoid duplication
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))  # Rotate x-axis labels

# Second plot
p2 <- df %>% filter(dist_to_precinct < 10) %>%
  ggplot(aes(x = dist_to_precinct, fill = crime_type)) +
  geom_histogram(binwidth = 1, position = "dodge", alpha = 0.7) +
  labs(x = "Distance (in miles)", y = "Count", fill = "Crime Type")  # Removed title to avoid duplication

# Combine the two plots with a single title
grid.arrange(p1, p2, ncol = 1, top = "Crime Count and Distance to Precinct")
```

```{r}
# Assign plots to variables
p1 <- ggplot(df, aes(x = Vict.Age, fill = as.factor(crime_type))) +
  geom_histogram(binwidth = 10, position = "dodge", color = "black") +
  labs(title = NULL, 
       x = "Age", 
       y = "Count", 
       fill = "Crime Type") +
  theme(legend.position="none")

p2 <- ggplot(df, aes(x = Vict.Sex, fill = as.factor(crime_type))) +
  geom_bar(position = "dodge", color = "black") +
  labs(title = NULL, 
       x = "Sex", 
       y = "Count") +  # Removed the fill legend title
  theme_minimal() +
  theme(legend.position="none")  # Remove the legend

p3 <- ggplot(df, aes(x = Vict.Descent, fill = as.factor(crime_type))) +
  geom_bar(position = "dodge", color = "black") +
  labs(title = NULL, 
       x = "Descent", 
       y = "Count", 
       fill = "Crime Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability

# Adjust the plot margins
margin_adjustment <- theme(plot.margin = margin(5, 5, 5, 5, "pt"))
p1 <- p1 + margin_adjustment
p2 <- p2 + margin_adjustment
p3 <- p3 + margin_adjustment

# Define a layout matrix similar to the previous one, but for the new plots
# 1 = p1, 2 = p2, 3 = p3
# The layout matrix arranges p1 and p2 side by side in the first row,
# and p3 (stretched) in the second row.
layout_matrix_new <- rbind(c(1, 2),
                           c(3, 3)) # Stretching p3 across the width of the grid

# Use grid.arrange to display the plots with the custom layout
grid.arrange(p1, p2, p3, layout_matrix = layout_matrix_new, 
             top="Distribution by Victim Age, Sex, and Descent")
```

```{r}
str(df)
```

```{r}
#Creating a Clean Df only the columsn which will be used ahead

#list of columns to keep
column_keep <- c("crime_type","time_hr", "Vict.Age", "Vict.Sex", "Vict.Descent", "dist_to_precinct", "weapons_binary", "AREA.NAME", "dt_weekday", "dt_month")

#create new df with these columns
df2 <- df[,names(df) %in% column_keep]

df2 <- df2[df$Vict.Sex != "H", ]

str(df2)
```

## Model 1 : Logistic

```{r}
#creating dataframe for logistic regression
df_logi <- df2[,!names(df2) %in% c("AREA.NAME", "dt_weekday", "dt_month")]
str(df_logi)
```

```{r}
model_logi <- glm(crime_type ~ ., data=df_logi, family="binomial")
```

```{r}
summary(model_logi)
```

```{r}
exp(coef(model_logi))
```

```{r}
exp(confint(model_logi))
```

```{r}
model_logi_1 <- glm(crime_type ~ time_hr + Vict.Age + Vict.Sex + dist_to_precinct + weapons_binary, family = "binomial", data = df_logi)
```

```{r}
model_logi_2 <- glm(crime_type ~ time_hr + Vict.Age + dist_to_precinct + weapons_binary, family = "binomial", data = df_logi)
```

```{r}
summary(model_logi_1)
```

```{r}
summary(model_logi_2)
```

```{r}
model_logi_interaction <- glm(crime_type ~ time_hr + Vict.Age + Vict.Sex + Vict.Descent + Vict.Sex * Vict.Descent + dist_to_precinct + weapons_binary, family = "binomial", data = df_logi)
```

```{r}
summary(model_logi_interaction)
```

```{r}
deviance_value <- deviance(model_logi)
deviance_value_1 <- deviance(model_logi_1)
deviance_value_2 <- deviance(model_logi_2)
deviance_value
deviance_value_1
deviance_value_2
```

```{r}
aic_value_base <- AIC(model_logi)
aic_value_alt_1 <- AIC(model_logi_1)
aic_value_alt_2 <- AIC(model_logi_2)
aic_value_base
aic_value_alt_1
aic_value_alt_2
```

```{r}
null_model <- glm(crime_type ~ 1, data = df_logi, family = "binomial")
null_deviance <- deviance(null_model)
model_deviance <- deviance(model_logi)
mcfaddens_pseudo_r2 <- 1 - (model_deviance / null_deviance)
mcfaddens_pseudo_r2
```

```{r}
roc_plot = roc(factor(df_logi$crime_type), fitted(model_logi))

# basic ROC plot
plot(roc_plot, main = "ROC Curve")

# calculate threshold
coords <- coords(roc_plot, "best")

# add  threshold and AOC value
text(x = coords$specificity, y = coords$sensitivity, labels = paste("Threshold:", coords$threshold), pos = 4, cex = 0.8)
text(x = coords$specificity, y = coords$sensitivity, labels = paste("AUC:", round(auc(roc_plot), 2)), pos = 2, cex = 0.8)
```

```{r}
predicted_probabilities <- fitted(model_logi)
predicted_classes <- ifelse(predicted_probabilities > 0.618, "1", "0")
```

```{r}
crime_type_numeric <- as.numeric(factor(df_logi$crime_type, levels = c("non-serious", "serious"))) - 1
```

```{r}
crime_type_factor <- factor(crime_type_numeric, levels = c("0", "1"))
predicted_factor <- factor(predicted_classes, levels = c("0", "1"))
```

```{r}
conf_matrix <- confusionMatrix(predicted_factor, crime_type_factor, positive = "1")
conf_matrix
```

do we require the below part? doesn't seem to be used, keeping it commented out

```{r}
#california_map <- map_data("county", "california")
```

Assesment

```{r}
vif(model_logi)
```

```{r}
roc_plot = roc(df_logi$crime_type, fitted(model_logi))

# basic ROC plot
plot(roc_plot, main = "ROC Curve")

# calculate threshold
coords <- coords(roc_plot, "best")

# add  threshold and AOC value
text(x = coords$specificity, y = coords$sensitivity, labels = paste("Threshold:", coords$threshold), pos = 4, cex = 0.8)
text(x = coords$specificity, y = coords$sensitivity, labels = paste("AUC:", round(auc(roc_plot), 2)), pos = 2, cex = 0.8)
```

```{r}
df_logi$predprobs <- predict(model_logi, type = "response")
plot(df_logi$predprobs, xlab = "Observations", ylab = "Predicted Probability", main = "Predicted Probabilities")
```

## Method

Modeling and Preliminary Insights:

The first research question is addressed using logistic regression, an ideal method for binary outcomes like 'serious' and 'non-serious'. Logistic regression excels in inferential analysis, allowing the identification of factors that influence the seriousness of crimes. Before constructing the model, it was crucial to address rows with blank values or symbols such as '-', and 'H' for two specific variables: victim sex and victim descent. Due to the impracticality of imputing these missing values and the large size of the dataset, they were either replaced with 'unknown' or removed during the model configuration. Typically, 'unknown' data is considered as missing values, but in this dataset, 'unknown' is viewed as systematically missing values. Consequently, we retained '-' and 'H' values for victim sex and descent in the dataset and replaced blank values with 'unknown'.

In our a priori selection, factors like time of occurrence, distance to the precinct, demographic information (gender, age, descent), and weapon usage were included, hypothesizing that these significantly influence crime seriousness. We also explored the interaction term with sex and descent, based on the hypothesis that specific genders and descents might be interrelated. However, the model with the interaction term did not yield statistically significant results, leading to its removal from the final model. Additionally, several assessment methods were considered for fitting the model to the dataset.

Firstly, regarding collinearity, we chose to use the Variance Inflation Factor (VIF) to assess collinearity within the model. We also employed deviance and the Akaike Information Criterion (AIC) to find the most fitting model by comparing two alternative models, excluding victim sex and descent. Based on the relationship between crime seriousness and 1, we evaluated the model's fit using McFadden's pseudo R\^2 value. Additionally, we assessed the model using the ROC curve and confusion matrix through prediction methods. These approaches helped us determine the extent to which the model fits the dataset and its effectiveness in addressing the research question.

## Results

Based on the logistic regression results for the model, we obtained the final outcome, which is expressed in an exponential form to showcase the odds ratios as follows:

+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
|                                                    | **Coefficient\ | **Standard Errors** | **p-values**    | **Confidence Interval**\ |
|                                                    | Estimates**    |                     |                 | (2.5%, 97.5%)            |
+:==================================================:+:==============:+:===================:+:===============:+:========================:+
| **(Intercept)**                                    | 1.1932         | 1.798e-02           | \< 2e-16 \*\*\* | (1.1519, 1.2361)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Time hours occurred**                            | 1.0159         | 3.704e-04           | \< 2e-16 \*\*\* | (1.0151, 1.0166)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Age**                                     | 0.9965         | 1.513e-04           | \< 2e-16 \*\*\* | (0.9962, 0.9968)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Sex: Male**                               | 1.8827         | 5.271e-03           | \< 2e-16 \*\*\* | (1.8634, 1.9023)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Sex: Unknown**                            | 3.4659         | 2.507e-02           | \< 2e-16 \*\*\* | (3.2995, 3.6402)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Black**                          | 0.7144         | 1.693e-02           | \< 2e-16 \*\*\* | (0.6910, 0.7385)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Chinese**                        | 1.6801         | 4.516e-02           | \< 2e-16 \*\*\* | (1.5385, 1.8365)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Cambodian**                      | 1.4699         | 3.002e-01           | 0.1994          | (0.8321, 2.7216)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Filipino**                       | 1.1828         | 4.074e-02           | 3.78e-05 \*\*\* | (1.0922, 1.2814)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Guamanian**                      | 1.0696         | 2.884e-01           | 0.8156          | (0.6120, 1.9082)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Hispanic/Latin/Mexican**         | 0.6354         | 1.635e-02           | \< 2e-16 \*\*\* | (0.6154, 0.6561)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: American Indian/Alaskan Native** | 1.0689         | 7.907e-02           | 0.3992          | (0.9164, 1.2495)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Japanese**                       | 1.7731         | 7.185e-02           | 1.56e-15 \*\*\* | (1.5423, 2.0443)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Korean**                         | 1.1302         | 3.635e-02           | 0.0008 \*\*     | (1.0526, 1.2138)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Laotian**                        | 0.5307         | 2.953e-01           | 0.0319 \*       | (0.2944, 0.9438)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Other**                          | 0.7804         | 1.782e-02           | \< 2e-16 \*\*\* | (0.7536, 0.8082)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Pacific Islander**               | 1.0433         | 1.446e-01           | 0.7694          | (0.7880, 1.3899)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Samoan**                         | 0.6829         | 3.072e-01           | 0.2145          | (0.3733, 1.2552)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Hawaiian**                       | 1.4184234      | 1.759e-01           | 0.0469 \*       | (1.0120, 2.0197)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Vietnamese**                     | 1.9475         | 8.509e-02           | 4.75e-15 \*\*\* | (1.6518, 2.3062)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: White**                          | 0.8616         | 1.659e-02           | \< 2e-16 \*\*\* | (0.8340, 0.8900)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Unknown**                        | 1.0460         | 2.853e-02           | 0.1153          | (0.9891, 1.1062)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Victim Descent: Asian Indian**                   | 1.8502         | 1.209e-01           | 3.61e-07 \*\*\* | (1.4663, 2.3569)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Distance to precinct**                           | 0.9998         | 5.826e-06           | \< 2e-16 \*\*\* | (0.9998, 0.9999)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+
| **Weapoon: Used**                                  | 0.5995         | 5.269e-03           | \< 2e-16 \*\*\* | (0.5933, 0.6057)         |
+----------------------------------------------------+----------------+---------------------+-----------------+--------------------------+

The model was refined using forward stepwise selection and cross-validation. The goodness of fit was indicated by a null deviance of 980739.3, leading to a significant model improvement with an AIC of 980789.3. However, the McFadden's pseudo R^2^ value of 0.09004, though low, suggests limited explanatory power.

The model's accuracy was approximately 61.87%, not sufficiently high to be definitive. A Kappa value of 0.2611, while slightly better than chance, also indicates modest performance. Sensitivity and specificity are crucial in evaluating the model. Sensitivity (true positive rate) effectively identifies actual serious cases, while specificity (true negative rate) accurately identifies non-serious cases. These metrics collectively offer a comprehensive view of the model's ability to distinguish between serious and non-serious cases. The following table briefly describes the results of the confusion matrix:

|                              |    **Value**     |
|------------------------------|:----------------:|
| **Accuracy**                 |      0.6187      |
| **95% Confidence Intervals** | (0.6177, 0.6198) |
| **Kappa**                    |      0.2611      |
| **Sensitivity**              |      0.5217      |
| **Specificity**              |      0.7558      |

The model's insights include:

-   Time hours occurred: Night or early morning crimes were more likely to be serious.

-   Distance to precinct: Closer proximity to certain precincts correlated with serious crimes.

-   Demographic Information: Men and younger individuals were more often victims of serious crimes, with certain racial groups being more susceptible. Among the various descents, individuals of Cambodian, Filipino, Japanese, Korean, Vietnamese, and Asian Indian descent were more likely to be victims of serious crimes compared to other racial groups.

-   Weapon Used: The presence of a weapon did not significantly increase the likelihood of a crime being serious. Instead, crimes committed without a weapon had a higher probability of occurring.

These results provide insights into the factors that influence the occurrence of serious crimes. While many variables show statistical significance, the study does have its limitations. To enhance the model, incorporating additional variables or exploring new datasets could be beneficial. A major challenge lies in managing the 'Unknown' categories within Demographic Information, which is essential for improving the study's accuracy and relevance. In our modeling configuration, we have removed all such values from the dataset.

Furthermore, although variables such as 'time hours occurred' and 'distance to precinct' show statistical significance, their probabilities of influencing serious crime occurrences are close to 1, indicating minimal impact. This finding warrants further investigation into the underlying reasons for this observation.

Consequently, given these limitations, it becomes imperative to examine other variables within the dataset or to consider integrating additional data, such as other Los Angeles crime datasets, to augment and refine the model. This approach could provide a more comprehensive understanding of the factors contributing to serious crime occurrences and enhance the predictive power of the model.

## Model 2 : Poisson

```{r}
df_pois <- df2[,names(df2) %in% c("AREA.NAME", "dt_weekday","dt_month") ]
str(df_pois)
```

```{r}
df_daily <- df_pois %>%
  group_by(dt_weekday,dt_month,AREA.NAME)%>%
  summarise(count = n())
```

We can skip the below part since we have a similar plot in the EDA section, moght help save space

```{r}
#| fig-width: 5.5
#| fig-height: 2
library(gridExtra)
library(ggplot2)
library(dplyr)

# Create the histogram plot
p1 <- ggplot(df_daily, aes(x = count, y = ..density..)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  labs(title = "Crime Counts (Proportions)",
       x = "Crime Count",
       y = "Proportion") +
  theme_minimal()

# Aggregate counts by weekday across all areas and months
weekday_counts <- df_daily %>%
  group_by(dt_weekday) %>%
  summarise(total_count = sum(count))

# Create the bar chart for weekday counts
p2 <- ggplot(weekday_counts, aes(x = dt_weekday, y = total_count, fill = dt_weekday)) +
  geom_bar(stat = "identity") +
  labs(title = "Crime Counts Weekday",
       x = "Day of the Week",
       y = "Total Count Crimes") +
  theme_minimal() +
  theme(legend.position = "none")

# Adjust plot margins
margin_adjustment <- theme(plot.margin = margin(5, 5, 5, 5, "pt"))
p1 <- p1 + margin_adjustment
p2 <- p2 + margin_adjustment

# Define a layout matrix to arrange the plots
# Here we arrange p1 on the left and p2 on the right in a single row
layout_matrix <- matrix(c(1, 2), nrow = 1)

# Use grid.arrange to display the plots side by side
grid.arrange(p1, p2, layout_matrix = layout_matrix, 
             top="Crime Count Distributions")
```

```{r}
#cross validation setup
set.seed(123)

split<-sample.split(df_daily$count,SplitRatio = 0.7)
train<-subset(df_daily,split==TRUE)
test<-subset(df_daily,split ==FALSE)
```

```{r}
#fitting the model 
model_pois <- glm(count ~ . , data = train, family = poisson)
model_forward <- step(model_pois, direction ="both")
summary(model_forward)
```

```{r}
#Testing the model, evaluation 
dispersiontest(model_forward)
```

```{r}
# Predicting the outputs
predictions <- predict(model_forward, newdata = test, type='response')

# Add predictions to the test dataset
test$predict <- predictions

# Display the first few rows of the test dataset with predictions
head(test)

# Summary of the model with exponentiated coefficients, confidence intervals, and p-values
exp_coef <- exp(coef(model_forward))
conf_int <- exp(confint(model_forward))
p_values <- summary(model_forward)$coefficients[, 4]

# Combine the exponentiated coefficients with their corresponding confidence intervals and p-values
results_summary <- cbind(exp_coef, conf_int, p_values)
```

```{r}
rmse(test$count, test$predict)
```

```{r}
#To calcualte the R2
rsq <- function (x, y) cor(x, y) ^ 2
rs <- rsq(test$count, test$predict)
rs
```

```{r}
summary(test$count)
```

```{r}
summary(test$predict)
```
